{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81586296",
   "metadata": {},
   "source": [
    "# quest 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7ca8772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayes' theorem, named after the Reverend Thomas Bayes, is a fundamental concept in probability theory and statistics. It describes the probability of an event, based on prior knowledge of conditions that might be related to the event"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a0917a",
   "metadata": {},
   "source": [
    "# quest 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36dd199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Bayes' theorem is expressed mathematically as:\n",
    "# p(A/B) = p(B/A) * p(A)/p(B)\n",
    "# P(A∣B) is the probability of event A occurring given that event B has occurred.\n",
    "\n",
    "# P(B∣A) is the probability of event B occurring given that event A has occurred.\n",
    "\n",
    "# P(B) are the probabilities of events A and B occurring independently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574999b5",
   "metadata": {},
   "source": [
    "# quest 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ff8b551",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Bayes' theorem is used in various practical applications across different fields. Here are a few examples:\n",
    "\n",
    "# Medical Diagnosis: In medical diagnosis, Bayes' theorem is used to update the probability of a patient having a particular disease based on new diagnostic test results and prior knowledge about the prevalence of the disease in the population. It helps doctors make more informed decisions about treatments and interventions.\n",
    "# Spam Filtering: In email spam filtering, Bayes' theorem is employed to classify emails as spam or non-spam. By analyzing the occurrence of certain words or phrases in spam and non-spam emails (using training data), the theorem can be used to calculate the probability that an email is spam given the words it contains.\n",
    "# Machine Learning: In machine learning, particularly in Bayesian statistics and probabilistic modeling, Bayes' theorem is used for inference and learning from data. It's applied in Bayesian methods for parameter estimation, model selection, and uncertainty quantification.\n",
    "# Weather Forecasting: Bayes' theorem is utilized in weather forecasting to update the probability of different weather outcomes based on observations such as temperature, humidity, and wind patterns. By incorporating new data into the forecasting model, meteorologists can provide more accurate predictions.\n",
    "# Fault Diagnosis in Engineering: In engineering, particularly in fault diagnosis systems, Bayes' theorem is used to infer the probability of different fault scenarios based on sensor data and prior knowledge about the system's behavior. This helps in detecting and diagnosing faults in machinery and systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad9dff9",
   "metadata": {},
   "source": [
    "# quest 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f071324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayes' theorem is closely related to conditional probability. Conditional probability is the probability of an event occurring given that another event has already occurred. Bayes' theorem provides a way to calculate conditional probabilities using prior probabilities and the likelihood of observing the events."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28c8517",
   "metadata": {},
   "source": [
    "# quest 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b23e6ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Choosing the appropriate type of Naive Bayes classifier for a given problem depends on various factors, including the nature of the data and the assumptions that can reasonably be made about the independence of features. Here are some considerations:\n",
    "\n",
    "# Nature of the Features:\n",
    "# Bernoulli Naive Bayes: If the features are binary or categorical, such as presence or absence of certain attributes.\n",
    "# Multinomial Naive Bayes: Suitable for features that represent counts or frequencies, such as word counts in text classification.\n",
    "# Gaussian Naive Bayes: Appropriate for continuous-valued features assumed to follow a Gaussian (normal) distribution.\n",
    "# Size of the Dataset:\n",
    "# Bernoulli and Multinomial Naive Bayes: These models are often preferred for datasets with a relatively large number of features and a moderate to large number of instances.\n",
    "# Gaussian Naive Bayes: It can handle continuous data well but may not perform as effectively as the other types for high-dimensional datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef46bb58",
   "metadata": {},
   "source": [
    "# quest 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918a47a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "To predict the class of the new instance using Naive Bayes, we'll calculate the conditional probabilities of each class given the values of features X1 = 3 and X2 = 4, and then choose the class with the highest probability.\n",
    "\n",
    "Given:\n",
    "\n",
    "Features: X1 = 3 and X2 = 4\n",
    "Classes: A and B\n",
    "Prior probabilities: P(A) = P(B) = 0.5 (assuming equal prior probabilities)\n",
    "    \n",
    "    First, let's calculate the conditional probabilities:\n",
    "\n",
    "For Class A:\n",
    "\n",
    "𝑃(𝑋1=3∣𝐴)=4/13\n",
    "𝑃(𝑋2=4∣𝐴)=3/13\n",
    "\n",
    " \n",
    "For Class B:\n",
    "\n",
    "𝑃(𝑋1=3∣𝐵)=1/9\n",
    "𝑃(𝑋2=4∣𝐵)=3/9\n",
    "\n",
    "\n",
    "For Class A:\n",
    "𝑃(𝐴∣𝑋1=3,𝑋2=4)≈0.496\n",
    "For Class B:\n",
    "P(B∣X1=3,X2=4)≈0.504\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
